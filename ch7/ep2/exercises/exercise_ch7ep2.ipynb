{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "spark = SparkSession.builder.master('local').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------------------------+\n",
      "|first(set_num)|(count(inventory_id) > CAST(1 AS BIGINT))|\n",
      "+--------------+-----------------------------------------+\n",
      "|        6800-1|                                     true|\n",
      "|        1958-1|                                     true|\n",
      "|        851097|                                     true|\n",
      "|       4428-10|                                     true|\n",
      "|        8383-1|                                     true|\n",
      "|       9509-10|                                     true|\n",
      "|        5576-1|                                    false|\n",
      "|        8805-0|                                    false|\n",
      "|        3886-2|                                    false|\n",
      "|        3402-1|                                     true|\n",
      "|       10131-1|                                     true|\n",
      "|        2854-1|                                     true|\n",
      "|        8380-1|                                     true|\n",
      "|        8601-1|                                     true|\n",
      "|       41545-1|                                     true|\n",
      "|        7890-1|                                     true|\n",
      "|        8621-1|                                     true|\n",
      "|        7235-2|                                     true|\n",
      "|        5610-1|                                     true|\n",
      "|       71000-0|                                    false|\n",
      "+--------------+-----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/22 19:27:42 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 6782015 ms exceeds timeout 120000 ms\n",
      "22/06/22 19:27:42 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "set_df = spark.read.csv('data/sets.csv',header=True, schema='set_num string,name string,year int,theme_id int,num_parts int')\n",
    "\n",
    "#1. Find the total number, average number, min and max number of parts, in all sets.\n",
    "# set_df.agg({'num_parts': 'avg'}).show()\n",
    "# set_df.agg({'num_parts': 'max'}).show()\n",
    "# set_df.agg({'num_parts': 'min'}).show()\n",
    "\n",
    "#2. Find the total number, average number, min and max number of parts, for each theme_id in sets.\n",
    "# set_df.groupBy('theme_id').agg({'num_parts': 'avg'}).show()\n",
    "# set_df.groupBy('theme_id').agg({'num_parts': 'max'}).show()\n",
    "# set_df.groupBy('theme_id').agg({'num_parts': 'min'}).show()\n",
    "\n",
    "set_df.createOrReplaceTempView(\"sets\")\n",
    "#3. Find all theme_ids that have more than 200 parts on average.\n",
    "# spark.sql('SELECT theme_id, avg(num_parts) > 200 AS avg_parts FROM sets GROUP BY theme_id').show(5)\n",
    "#4. Find how many total parts each theme had every year.\n",
    "# spark.sql('SELECT year, theme_id, sum(num_parts) AS total_parts FROM sets GROUP BY theme_id, year').show(20)\n",
    "#5. Find the set with the most number of parts each year.\n",
    "# spark.sql('SELECT year, first(name), max(num_parts) FROM sets GROUP BY year').show(20)\n",
    "\n",
    "\n",
    "#6. How many sets do we have with more than one version in set_inventories?\n",
    "set_inv_df = spark.read.csv('data/inventory_sets.csv',header=True, schema='inventory_id int,set_num string, quantity int')\n",
    "set_inv_df.createOrReplaceTempView(\"sets_inventory\")\n",
    "spark.sql('SELECT first(set_num), count(inventory_id) > 1 FROM sets_inventory GROUP BY inventory_id').show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5157bb98d5712e9bc3d926e146efc27a3cbd5ed86683426e8c68a1e85535f153"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
